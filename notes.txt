print(tweet.id)
print(tweet.created_at)
print(tweet.text)
print(tweet.user.id)
print(tweet.user.name)
print(tweet.user.screen_name)
print(tweet.user.location)
print(tweet.user.followers_count)
print(tweet.user.created_at)
print(tweet.user.geo_enabled)
print(tweet.geo)
print(tweet.coordinates)
print(tweet.place)
print(tweet.retweet_count)
print(tweet.favorite_count)

restrict by location
no replies
no retweets
start and end date
tweet needs extended mode
Only get tweets with locations


https://developer.twitter.com/en/docs/twitter-api/premium/rules-and-filtering/operators-by-product

we can use place, place_country and some similar. There doesn't seem to be any way of filtering retweets or replies without being on a paid tier.
This can be a city, or a country. We can also restrict the language down to restrict english inputs if we need that.
We can set a start and end date.
Full_text is stored differently for retweets and tweets so we could take all, or choose only original content. we would hit the same API limit though.

Limit seems to be at 300 per 15 minutes.
We can run this every 15 minutes with different locations, and different time periods. I would ask here does time periods give us much?

Twarc

twarc2 configure
YYYY-MM-DD
-is_retweet -RT
https://twittercommunity.com/t/exclude-retweets-in-api-v2/156357/5

# get all tweets, january London
twarc2 search --archive --max-results 100 --start-time "2019-01-01" --end-time "2019-01-30" "(vegan OR plant-based OR plant based OR veganism) -is:retweet --geocode 51.507351,-0.127758,10mi" data1.jsonl
twarc2 csv data1.jsonl dataManchester.csv

How much do people actually tweet?

# get all tweets, january Preston 3 hours, about 1,200,000 just for 1 month of vegan tweets from Preston... file size?
# Took about 32 hours with some hiccups, downloaded 1,187,582 Tweets (1.2 mill) this file is about 4.2 GB as well.
twarc2 search --archive --max-results 100 --start-time "2019-01-01" --end-time "2019-01-30" "vegan OR plant-based OR plant based OR veganism -is:retweet --geocode 53.763208,-2.699540,3mi" dataPreston.jsonl

# CSV conversion here took about 10 minutes luckily!
twarc2 csv dataPreston.jsonl PrestonJan2019.csv

# Processing took about 2 minutes to drop all retweets and replies. 37% of these tweets are original content.
# Once tidied for our research question this file is only 135MB, too big to store on Github sadly.

# get 250 tweets each three day period, london
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-01" --end-time "2021-01-30" "(vegan OR plant-based OR plant based OR veganism) point_radius:[51.507351 -0.127758 25mi] -is:retweet" data1.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-04" --end-time "2019-01-6" "vegan OR plant-based OR plant based OR veganism --geocode 48.8566, 2.3522,10mi -is:retweet" data2.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-07" --end-time "2019-01-9" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data3.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-10" --end-time "2019-01-12" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data4.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-13" --end-time "2019-01-15" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data5.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-16" --end-time "2019-01-18" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data6.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-19" --end-time "2019-01-21" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data7.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-22" --end-time "2019-01-24" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data8.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-25" --end-time "2019-01-27" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data9.jsonl
twarc2 search --archive --limit 250 --max-results 100 --start-time "2019-01-28" --end-time "2019-01-30" "vegan OR plant-based OR plant based OR veganism --geocode 51.507351,-0.127758,10mi -is:retweet" data10.jsonl

# new search structure
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) point_radius:[-0.127758 51.507351 5mi]' londonGeoPointRadius.jsonl
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) place:london' londonGeoPlace.jsonl
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) point_radius:[-2.242631 53.480759 5mi]' manchesterGeoPointRadius.jsonl
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) place:manchester' manchesterGeoPlace.jsonl
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) point_radius:[-2.703440 53.757729 5mi]' prestonGeoPointRadius.jsonl
twarc2 search --archive --start-time "2019-01-01" --end-time "2019-01-30" '(vegan OR plant-based OR "plant based" OR veganism) place:preston' prestonGeoPlace.jsonl

# convert jsonl to csv
twarc2 csv londonGeoPointRadius.jsonl londonGeoPointRadius.csv
twarc2 csv londonGeoPlace.jsonl londonGeoPlace.csv
twarc2 csv manchesterGeoPointRadius.jsonl manchesterGeoPointRadius.csv
twarc2 csv manchesterGeoPlace.jsonl manchesterGeoPlace.csv
twarc2 csv prestonGeoPointRadius.jsonl prestonGeoPointRadius.csv
twarc2 csv prestonGeoPlace.jsonl prestonGeoPlace.csv

pip install twarc-csv
twarc2 csv data.jsonl data.csv

twarc2 csv data1.jsonl data1.csv
twarc2 csv data2.jsonl data2.csv
twarc2 csv data3.jsonl data3.csv
twarc2 csv data4.jsonl data4.csv
twarc2 csv data5.jsonl data5.csv
twarc2 csv data6.jsonl data6.csv
twarc2 csv data7.jsonl data7.csv
twarc2 csv data8.jsonl data8.csv
twarc2 csv data9.jsonl data9.csv
twarc2 csv data10.jsonl data10.csv


The API itself delivers those tweets truncated, but you can find the full retweeted text inside the text field of the referenced_tweets object.


https://github.com/alblaine/twarc-tutorial
https://github.com/jeffcsauer/twarc-v2-tutorials/blob/master/twarc_fas.md
https://data.page/json/csv
https://github.com/pbinkley/twarc-report

Explore get old tweets
https://pypi.org/project/GetOldTweets3/
https://github.com/Mottl/GetOldTweets3/issues/98
https://github.com/twitterdev/search-tweets-python